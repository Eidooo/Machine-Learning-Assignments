{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38ff21b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c096ec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data=pd.read_csv(\"fraud data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9d33440",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data[\"type\"] = my_data[\"type\"].map({\"CASH_OUT\": 1, \"PAYMENT\": 2,\"CASH_IN\": 3, \"TRANSFER\": 4,\"DEBIT\": 5})\n",
    "my_data[\"isFraud\"] = my_data[\"isFraud\"].map({0: \"No Fraud\", 1: \"Fraud\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ed78c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.00</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>No Fraud</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.00</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>No Fraud</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Fraud</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Fraud</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.00</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>No Fraud</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362615</th>\n",
       "      <td>743</td>\n",
       "      <td>1</td>\n",
       "      <td>339682.13</td>\n",
       "      <td>C786484425</td>\n",
       "      <td>339682.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C776919290</td>\n",
       "      <td>0.00</td>\n",
       "      <td>339682.13</td>\n",
       "      <td>Fraud</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362616</th>\n",
       "      <td>743</td>\n",
       "      <td>4</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>C1529008245</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1881841831</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Fraud</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362617</th>\n",
       "      <td>743</td>\n",
       "      <td>1</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>C1162922333</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1365125890</td>\n",
       "      <td>68488.84</td>\n",
       "      <td>6379898.11</td>\n",
       "      <td>Fraud</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362618</th>\n",
       "      <td>743</td>\n",
       "      <td>4</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>C1685995037</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C2080388513</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Fraud</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362619</th>\n",
       "      <td>743</td>\n",
       "      <td>1</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>C1280323807</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C873221189</td>\n",
       "      <td>6510099.11</td>\n",
       "      <td>7360101.63</td>\n",
       "      <td>Fraud</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6362620 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         step  type      amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0           1     2     9839.64  C1231006815      170136.00       160296.36   \n",
       "1           1     2     1864.28  C1666544295       21249.00        19384.72   \n",
       "2           1     4      181.00  C1305486145         181.00            0.00   \n",
       "3           1     1      181.00   C840083671         181.00            0.00   \n",
       "4           1     2    11668.14  C2048537720       41554.00        29885.86   \n",
       "...       ...   ...         ...          ...            ...             ...   \n",
       "6362615   743     1   339682.13   C786484425      339682.13            0.00   \n",
       "6362616   743     4  6311409.28  C1529008245     6311409.28            0.00   \n",
       "6362617   743     1  6311409.28  C1162922333     6311409.28            0.00   \n",
       "6362618   743     4   850002.52  C1685995037      850002.52            0.00   \n",
       "6362619   743     1   850002.52  C1280323807      850002.52            0.00   \n",
       "\n",
       "            nameDest  oldbalanceDest  newbalanceDest   isFraud  isFlaggedFraud  \n",
       "0        M1979787155            0.00            0.00  No Fraud               0  \n",
       "1        M2044282225            0.00            0.00  No Fraud               0  \n",
       "2         C553264065            0.00            0.00     Fraud               0  \n",
       "3          C38997010        21182.00            0.00     Fraud               0  \n",
       "4        M1230701703            0.00            0.00  No Fraud               0  \n",
       "...              ...             ...             ...       ...             ...  \n",
       "6362615   C776919290            0.00       339682.13     Fraud               0  \n",
       "6362616  C1881841831            0.00            0.00     Fraud               0  \n",
       "6362617  C1365125890        68488.84      6379898.11     Fraud               0  \n",
       "6362618  C2080388513            0.00            0.00     Fraud               0  \n",
       "6362619   C873221189      6510099.11      7360101.63     Fraud               0  \n",
       "\n",
       "[6362620 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1965f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=my_data.drop('isFraud',axis=1)\n",
    "y=my_data['isFraud']\n",
    "for i in range(1,7):\n",
    "    max_x=max(x.iloc[:,i])\n",
    "    min_x=min(x.iloc[:,i])\n",
    "    x.iloc[:,i]=(x.iloc[:,i]-min_x)/(max_x-min_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b90a0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=42)\n",
    "x_cv, x_test_new=np.split(x_test, 2)\n",
    "y_cv , y_test_new=np.split(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad396237",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new=np.zeros(len(y_train))\n",
    "for i in range (len(y_train)):\n",
    "    if y_train.iloc[i] == 'Fraud':\n",
    "        y_train_new[i] =1 \n",
    "y_train_new=pd.DataFrame(y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35007f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cv_new=np.zeros(len(y_cv))\n",
    "for i in range (len(y_cv)):\n",
    "    if y_cv.iloc[i] == 'Fraud':\n",
    "        y_cv_new[i] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d30b35fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_new_1=np.zeros(len(y_cv))\n",
    "for i in range (len(y_test_new)):\n",
    "    if y_test_new.iloc[i] == 'Fraud':\n",
    "        y_test_new_1[i] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7624d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateXvector(X):#add coloumn of 1 in X features\n",
    "    \"\"\" Taking the original independent variables matrix and add a row of 1 which corresponds to x_0\n",
    "        Parameters:\n",
    "          X:  independent variables matrix\n",
    "        Return value: the matrix that contains all the values in the dataset, not include the outcomes variables.  \"\"\"\n",
    "    vectorX = np.c_[np.ones((len(X), 1)), X]\n",
    "    return vectorX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d04cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_init(X):\n",
    "    \"\"\" Generate an initial value of vector Î¸ from the original independent variables matrix\n",
    "         Parameters:\n",
    "          X:  independent variables matrix\n",
    "        Return value: a vector of theta filled with initial guess\n",
    "    \"\"\"\n",
    "    theta = np.random.randn(X+1, 1)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8f11c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_function(X):\n",
    "    \"\"\" Calculate the sigmoid value of the inputs\n",
    "         Parameters:\n",
    "          X:  values\n",
    "        Return value: the sigmoid value\n",
    "    \"\"\"\n",
    "    return 1/(1+math.e**(-X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de7195ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistics_Regression(X,y,learningrate, iterations):\n",
    "        \n",
    "    y_new = y\n",
    "    cost_lst = []\n",
    "    vectorX = generateXvector(X)\n",
    "    theta = theta_init(len(X.iloc[0,:]))\n",
    "    m = len(X)\n",
    "    for i in range(iterations):\n",
    "        gradients = 2/m * vectorX.T.dot(sigmoid_function(vectorX.dot(theta)) - y_new)\n",
    "        theta = theta - learningrate * gradients\n",
    "        y_pred = sigmoid_function(vectorX.dot(theta))\n",
    "        cost_value = - np.sum(np.dot(y_new.T,np.log(y_pred)+ np.dot((1-y_new).T,np.log(1-y_pred)))) /(len(y_pred))\n",
    "        cost_lst.append(cost_value)\n",
    "        \n",
    "    return theta, cost_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc2feb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1, cost_value1=Logistics_Regression(x_train,y_train_new,0.03, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40a35b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_regularization(y_pred,y_test,theta):\n",
    "    cost_reg=100\n",
    "    best_lamda=0\n",
    "    lamda=np.array([0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24])\n",
    "    cost_lst = []\n",
    "    m = len(x)\n",
    "    N = len(y_test)\n",
    "    for i in range(np.size(lamda)):\n",
    "        term=(lamda[i]/2*N)*(np.sum(theta**2))\n",
    "        cost_value = (- np.sum(np.dot(y_test.T,np.log(y_pred)+ np.dot((1-y_test).T,np.log(1-y_pred)))) /(len(y_pred)))+term\n",
    "        cost_lst.append(cost_value)\n",
    "        if cost_value<cost_reg:\n",
    "            cost_reg=cost_value\n",
    "            best_lamda=lamda[i]\n",
    "    return best_lamda,cost_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "540bc719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_pred,y_test):\n",
    "    cost_value = (- np.sum(np.dot(y_test.T,np.log(y_pred)+ np.dot((1-y_test).T,np.log(1-y_pred)))) /(len(y_pred)))\n",
    "    return cost_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35b13dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Win-10\\AppData\\Local\\Temp/ipykernel_11480/652476340.py:7: RuntimeWarning: overflow encountered in power\n",
      "  return 1/(1+math.e**(-X))\n",
      "C:\\Users\\Win-10\\AppData\\Local\\Temp/ipykernel_11480/46542404.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  cost_value = - np.sum(np.dot(y_new.T,np.log(y_pred)+ np.dot((1-y_new).T,np.log(1-y_pred)))) /(len(y_pred))\n",
      "C:\\Users\\Win-10\\AppData\\Local\\Temp/ipykernel_11480/2464514834.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "  cost_value = (- np.sum(np.dot(y_test.T,np.log(y_pred)+ np.dot((1-y_test).T,np.log(1-y_pred)))) /(len(y_pred)))+term\n"
     ]
    }
   ],
   "source": [
    "cost_cv=100\n",
    "theta1_cv=[]\n",
    "for j in range(9):\n",
    "    vectorX=generateXvector(x_cv.iloc[:,0:j])\n",
    "    theta2, cost_value1=Logistics_Regression(x_train.iloc[:,0:j],y_train_new,0.03, 100)\n",
    "   \n",
    "    y_pred = sigmoid_function(vectorX.dot(theta2))#calculate hypothesis using best thetas\n",
    "    best_lamda,cost_reg=root_regularization(y_pred,y_cv_new,theta2)\n",
    "    if cost_value1<cost_cv:\n",
    "        cost_cv=cost_value1\n",
    "        theta1_cv=theta2\n",
    "    if cost_reg<cost_cv:\n",
    "        cost_cv=cost_reg\n",
    "        theta1_cv=theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c5959e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Win-10\\AppData\\Local\\Temp/ipykernel_11480/652476340.py:7: RuntimeWarning: overflow encountered in power\n",
      "  return 1/(1+math.e**(-X))\n",
      "C:\\Users\\Win-10\\AppData\\Local\\Temp/ipykernel_11480/1897399221.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  cost_value = (- np.sum(np.dot(y_test.T,np.log(y_pred)+ np.dot((1-y_test).T,np.log(1-y_pred)))) /(len(y_pred)))\n"
     ]
    }
   ],
   "source": [
    "y_pred_test=sigmoid_function(np.dot(x_test_new.iloc[:,0:np.size(theta1_cv)], theta1_cv))\n",
    "cost_y_test=rmse(y_pred_test,y_test_new_1)\n",
    "cost_test_reg=rmse(y_pred_test,y_test_new_1)+(best_lamda/2*len(y_cv))*(np.sum(theta1_cv**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90c1a3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.9994090484737419 per iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.9982538639742747 per iteration\n",
      "Accuracy is  0.9994467687839287 per iteration\n",
      "Accuracy is  0.9994027617553775 per iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.9994153351921063 per iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.9992471654758575 per iteration\n",
      "Accuracy is  0.9981925684702214 per iteration\n",
      "Accuracy is  0.9995394978798042 per iteration\n",
      "Accuracy is  0.9993163193778664 per iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.9943843888209574 per iteration\n"
     ]
    }
   ],
   "source": [
    "skfolds = KFold(n_splits=10)\n",
    "splits = skfolds.split(x, y)\n",
    "for i, (train_index, test_index) in enumerate(splits): #split and shuffle the data  \n",
    "  x_train = x.iloc[train_index]\n",
    "  y_train = y.iloc[train_index]\n",
    "  x_test  = x.iloc[test_index]\n",
    "  y_test  = y.iloc[test_index]\n",
    "  clf = LogisticRegression()\n",
    "  clf.fit(x_train, y_train)\n",
    "  y_pred = clf.predict(x_test)\n",
    "  accuracy = np.mean(y_pred == y_test)\n",
    "  print(\"Accuracy is \", accuracy , \"per iteration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "718eb93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.998742499554429\n",
      "[SPLIT 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.9987099657971195\n",
      "[SPLIT 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.9987750333117384\n",
      "[SPLIT 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.9988146396249848\n",
      "[SPLIT 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.998823126692109\n",
      "[SPLIT 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.9977679013463318\n",
      "[SPLIT 6]\n",
      "Accuracy is : 0.9988061525578605\n",
      "[SPLIT 7]\n",
      "Accuracy is : 0.9988301975933472\n",
      "[SPLIT 8]\n",
      "Accuracy is : 0.9990183278473797\n",
      "[SPLIT 9]\n"
     ]
    }
   ],
   "source": [
    "skfolds_1 = StratifiedKFold(n_splits=9)\n",
    "splits_1 = skfolds_1.split(x, y)\n",
    "for i, (train_index, test_index) in enumerate(splits_1): #split and shuffle the data \n",
    "  x_train = x.iloc[train_index]\n",
    "  y_train = y.iloc[train_index]\n",
    "  x_test  = x.iloc[test_index]\n",
    "  y_test  = y.iloc[test_index]\n",
    "  clf_1 = LogisticRegression()\n",
    "  clf_1.fit(x_train, y_train)\n",
    "  y_pred_1 = clf_1.predict(x_test)\n",
    "  accuracy = np.mean(y_pred_1 == y_test)\n",
    "  print(\"Accuracy is :\",  accuracy)\n",
    "  print(\"[SPLIT %d]\"%(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "450e2840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1270878       0]\n",
      " [   1646       0]]\n",
      "0.9987065076965149\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.confusion_matrix(y_test_new_1,np.round((y_pred_test))))\n",
    "print(accuracy_score(y_test_new_1, np.round((y_pred_test))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f180d182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fpr:  [0.00000000e+00 7.86857590e-07 7.78989014e-05 ... 9.83906402e-01\n",
      " 9.83906402e-01 1.00000000e+00]\n",
      "tpr:  [0.         0.         0.         ... 0.81773998 0.81834751 1.        ]\n",
      "auc:  0.3496749903847054\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, _ = metrics.roc_curve(y_test_new_1,  y_pred_test)\n",
    "auc = metrics.roc_auc_score(y_test_new_1, y_pred_test)\n",
    "print(\"fpr: \", fpr)\n",
    "print(\"tpr: \", tpr)\n",
    "print(\"auc: \",auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d88e72d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr,tpr)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dcaa7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
